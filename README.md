# scrapping-with-python
This script employs three essential Python modules: requests for sending HTTP requests, BeautifulSoup from the bs4 package for parsing and navigating HTML content, and pandas for data manipulation and storage. The script begins by defining the URL for Jumia Kenya's homepage and sending a GET request to retrieve its HTML content. If the request is successful, the script uses BeautifulSoup to parse the HTML and extract product details such as titles and prices from specific HTML elements. It iterates over each product link, gathering relevant information and storing it in a dictionary, which is then appended to a list. This list is converted into a pandas DataFrame, providing a structured format for the data. Finally, the DataFrame is saved as an Excel file named Jumia.xlsx, allowing for easy analysis and reporting. If the page retrieval fails, the script outputs an error message with the corresponding status code.
